{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:00.338335Z",
     "iopub.status.busy": "2024-10-21T16:54:00.337520Z",
     "iopub.status.idle": "2024-10-21T16:54:00.344043Z",
     "shell.execute_reply": "2024-10-21T16:54:00.343005Z",
     "shell.execute_reply.started": "2024-10-21T16:54:00.338271Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:01.559254Z",
     "iopub.status.busy": "2024-10-21T16:54:01.558469Z",
     "iopub.status.idle": "2024-10-21T16:54:01.566228Z",
     "shell.execute_reply": "2024-10-21T16:54:01.565369Z",
     "shell.execute_reply.started": "2024-10-21T16:54:01.559207Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "LR = 0.0002\n",
    "NUM_EPOCHS = 3\n",
    "IMAGE_SIZE = 256\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:03.230404Z",
     "iopub.status.busy": "2024-10-21T16:54:03.229522Z",
     "iopub.status.idle": "2024-10-21T16:54:03.239141Z",
     "shell.execute_reply": "2024-10-21T16:54:03.238249Z",
     "shell.execute_reply.started": "2024-10-21T16:54:03.230351Z"
    }
   },
   "outputs": [],
   "source": [
    "class DatasetClass(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.sketch_paths = []\n",
    "        self.photo_paths = []\n",
    "\n",
    "        for split in ['train', 'val', 'test']:\n",
    "            sketch_folder = os.path.join(root_dir, split, 'sketches')\n",
    "            photo_folder = os.path.join(root_dir, split, 'photos')\n",
    "\n",
    "            # Match sketch and photo filenames\n",
    "            for sketch_file in os.listdir(sketch_folder):\n",
    "                self.sketch_paths.append(os.path.join(sketch_folder, sketch_file))\n",
    "                self.photo_paths.append(os.path.join(photo_folder, sketch_file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sketch_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sketch = Image.open(self.sketch_paths[idx]).convert('RGB')\n",
    "        photo = Image.open(self.photo_paths[idx]).convert('RGB')   # Convert photo to RGB\n",
    "\n",
    "        if self.transform:\n",
    "            sketch = self.transform(sketch)\n",
    "            photo = self.transform(photo)\n",
    "\n",
    "        return sketch, photo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:04.387999Z",
     "iopub.status.busy": "2024-10-21T16:54:04.387640Z",
     "iopub.status.idle": "2024-10-21T16:54:04.393381Z",
     "shell.execute_reply": "2024-10-21T16:54:04.392290Z",
     "shell.execute_reply.started": "2024-10-21T16:54:04.387962Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocess_steps = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:05.337325Z",
     "iopub.status.busy": "2024-10-21T16:54:05.336698Z",
     "iopub.status.idle": "2024-10-21T16:54:05.440916Z",
     "shell.execute_reply": "2024-10-21T16:54:05.440094Z",
     "shell.execute_reply.started": "2024-10-21T16:54:05.337271Z"
    }
   },
   "outputs": [],
   "source": [
    "data_set = DatasetClass(root_dir='/kaggle/input/person-face-sketches', transform=preprocess_steps)\n",
    "train_loader = DataLoader(data_set, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:06.096703Z",
     "iopub.status.busy": "2024-10-21T16:54:06.096359Z",
     "iopub.status.idle": "2024-10-21T16:54:06.105835Z",
     "shell.execute_reply": "2024-10-21T16:54:06.104834Z",
     "shell.execute_reply.started": "2024-10-21T16:54:06.096671Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 3, kernel_size=7, stride=1, padding=3),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:06.711334Z",
     "iopub.status.busy": "2024-10-21T16:54:06.710786Z",
     "iopub.status.idle": "2024-10-21T16:54:06.718817Z",
     "shell.execute_reply": "2024-10-21T16:54:06.717901Z",
     "shell.execute_reply.started": "2024-10-21T16:54:06.711285Z"
    }
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:07.494568Z",
     "iopub.status.busy": "2024-10-21T16:54:07.493810Z",
     "iopub.status.idle": "2024-10-21T16:54:07.558249Z",
     "shell.execute_reply": "2024-10-21T16:54:07.557282Z",
     "shell.execute_reply.started": "2024-10-21T16:54:07.494527Z"
    }
   },
   "outputs": [],
   "source": [
    "generator_A2B = Generator().to(DEVICE)\n",
    "generator_B2A = Generator().to(DEVICE)\n",
    "discriminator_A = Discriminator().to(DEVICE)\n",
    "discriminator_B = Discriminator().to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:07.944060Z",
     "iopub.status.busy": "2024-10-21T16:54:07.943453Z",
     "iopub.status.idle": "2024-10-21T16:54:07.952643Z",
     "shell.execute_reply": "2024-10-21T16:54:07.951671Z",
     "shell.execute_reply.started": "2024-10-21T16:54:07.944023Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    generator_A2B = nn.DataParallel(generator_A2B)\n",
    "    generator_B2A = nn.DataParallel(generator_B2A)\n",
    "    discriminator_A = nn.DataParallel(discriminator_A)\n",
    "    discriminator_B = nn.DataParallel(discriminator_B)\n",
    "\n",
    "criterion_GAN = nn.MSELoss()\n",
    "criterion_cycle = nn.L1Loss()\n",
    "\n",
    "optimizer_G = optim.Adam(list(generator_A2B.parameters()) + list(generator_B2A.parameters()), lr=LR, betas=(0.5, 0.999))\n",
    "optimizer_D_A = optim.Adam(discriminator_A.parameters(), lr=LR, betas=(0.5, 0.999))\n",
    "optimizer_D_B = optim.Adam(discriminator_B.parameters(), lr=LR, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:08.703638Z",
     "iopub.status.busy": "2024-10-21T16:54:08.703279Z",
     "iopub.status.idle": "2024-10-21T16:54:08.713295Z",
     "shell.execute_reply": "2024-10-21T16:54:08.712358Z",
     "shell.execute_reply.started": "2024-10-21T16:54:08.703602Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_results(sketch, generated_photo, real_photo, generated_sketch, step):\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10))\n",
    "\n",
    "    axes[0, 0].imshow(((sketch.cpu().detach().numpy().transpose(1, 2, 0)) + 1) / 2)\n",
    "    axes[0, 0].axis('off')\n",
    "    axes[0, 0].set_title('Sketch')\n",
    "\n",
    "    axes[0, 1].imshow(((generated_photo.cpu().detach().numpy().transpose(1, 2, 0)) + 1) / 2)\n",
    "    axes[0, 1].axis('off')\n",
    "    axes[0, 1].set_title('Generated Photo')\n",
    "\n",
    "    axes[1, 0].imshow(((real_photo.cpu().detach().numpy().transpose(1, 2, 0)) + 1) / 2)\n",
    "    axes[1, 0].axis('off')\n",
    "    axes[1, 0].set_title('Real Photo')\n",
    "\n",
    "    axes[1, 1].imshow(((generated_sketch.cpu().detach().numpy().transpose(1, 2, 0)) + 1) / 2)\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].set_title('Generated Sketch')\n",
    "\n",
    "    plt.suptitle(f'Step {step}')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:09.611791Z",
     "iopub.status.busy": "2024-10-21T16:54:09.611424Z",
     "iopub.status.idle": "2024-10-21T16:54:09.618276Z",
     "shell.execute_reply": "2024-10-21T16:54:09.617356Z",
     "shell.execute_reply.started": "2024-10-21T16:54:09.611757Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_model_weights(epoch, save_dir=\"model_weights\"):\n",
    "    if not os.path.exists(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "\n",
    "    torch.save(generator_A2B.state_dict(), os.path.join(save_dir, f\"generator_A2B_epoch_{epoch+1}.pth\"))\n",
    "    torch.save(generator_B2A.state_dict(), os.path.join(save_dir, f\"generator_B2A_epoch_{epoch+1}.pth\"))\n",
    "    torch.save(discriminator_A.state_dict(), os.path.join(save_dir, f\"discriminator_A_epoch_{epoch+1}.pth\"))\n",
    "    torch.save(discriminator_B.state_dict(), os.path.join(save_dir, f\"discriminator_B_epoch_{epoch+1}.pth\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:54:10.556854Z",
     "iopub.status.busy": "2024-10-21T16:54:10.555939Z",
     "iopub.status.idle": "2024-10-21T16:59:13.732008Z",
     "shell.execute_reply": "2024-10-21T16:59:13.730714Z",
     "shell.execute_reply.started": "2024-10-21T16:54:10.556796Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    for i, (sketch, photo) in enumerate(train_loader):  # Use train_loader instead of dataloader\n",
    "        sketch = sketch.to(DEVICE)\n",
    "        photo = photo.to(DEVICE)\n",
    "\n",
    "        optimizer_G.zero_grad()\n",
    "\n",
    "        # Generator forward pass A2B is sketch to photo\n",
    "        fake_photo = generator_A2B(sketch)\n",
    "        reconstructed_sketch = generator_B2A(fake_photo)\n",
    "        loss_cycle_A = criterion_cycle(reconstructed_sketch, sketch)\n",
    "        \n",
    "        #B2A is photo to sketch\n",
    "        fake_sketch = generator_B2A(photo)\n",
    "        reconstructed_photo = generator_A2B(fake_sketch)\n",
    "        loss_cycle_B = criterion_cycle(reconstructed_photo, photo)\n",
    "\n",
    "        # GAN loss\n",
    "        loss_GAN_A = criterion_GAN(discriminator_B(fake_photo), torch.ones_like(discriminator_B(fake_photo)))\n",
    "        loss_GAN_B = criterion_GAN(discriminator_A(fake_sketch), torch.ones_like(discriminator_A(fake_sketch)))\n",
    "\n",
    "        # Total generator loss\n",
    "        loss_G = loss_GAN_A + loss_GAN_B + 10.0 * (loss_cycle_A + loss_cycle_B)\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Discriminator updates\n",
    "        optimizer_D_A.zero_grad()\n",
    "        optimizer_D_B.zero_grad()\n",
    "\n",
    "        loss_D_A = criterion_GAN(discriminator_A(photo), torch.ones_like(discriminator_A(photo))) + \\\n",
    "                    criterion_GAN(discriminator_A(fake_sketch.detach()), torch.zeros_like(discriminator_A(fake_sketch.detach())))\n",
    "\n",
    "        loss_D_B = criterion_GAN(discriminator_B(sketch), torch.ones_like(discriminator_B(sketch))) + \\\n",
    "                    criterion_GAN(discriminator_B(fake_photo.detach()), torch.zeros_like(discriminator_B(fake_photo.detach())))\n",
    "\n",
    "        loss_D_A.backward()\n",
    "        loss_D_B.backward()\n",
    "        optimizer_D_A.step()\n",
    "        optimizer_D_B.step()\n",
    "\n",
    "        if (i + 1) % 2 == 0:\n",
    "            visualize_results(sketch[0], fake_photo[0], photo[0], fake_sketch[0], i+1)\n",
    "            \n",
    "    \n",
    "\n",
    "    save_model_weights(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-21T16:59:24.213149Z",
     "iopub.status.busy": "2024-10-21T16:59:24.212767Z",
     "iopub.status.idle": "2024-10-21T16:59:24.283465Z",
     "shell.execute_reply": "2024-10-21T16:59:24.282653Z",
     "shell.execute_reply.started": "2024-10-21T16:59:24.213113Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "torch.save(generator_A2B.state_dict(), \"generator_A2B.pth\")\n",
    "torch.save(generator_B2A.state_dict(), \"generator_B2A.pth\")\n",
    "torch.save(discriminator_A.state_dict(), \"discriminator_A.pth\")\n",
    "torch.save(discriminator_B.state_dict(), \"discriminator_B.pth\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 2151228,
     "sourceId": 3724153,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
